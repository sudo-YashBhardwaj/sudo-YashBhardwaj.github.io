---
title: "Real-Time Multimodal Emotion Recognition and Summarization"
excerpt: "Production-ready real-time emotion recognition system processing video, audio, and text in parallel with sub-300ms latency, implementing advanced fusion algorithms and multi-threaded architecture for live emotion analysis.<br/><img src='/images/emotion_recognition.png' width='600'>"
collection: portfolio
---

A production-ready real-time multimodal emotion recognition system processing video, audio, and text streams concurrently with sub-300ms latency per frame.

**Innovation Highlights:** (1) Parallel processing with dedicated pipelines for video (MTCNN + DeepFace ensemble), audio (Whisper + RoBERTa), and text (RoBERTa), (2) Late fusion engine with priority-based selection (Text > Video > Audio) and confidence scoring, (3) Multi-threaded architecture with queue-based buffering and timestamp synchronization.

**Technical Excellence:** Real-time visualization with OpenCV, temporal emotion tracking for pattern analysis, and performance optimization achieving ~100-300ms latency per frame with ~2-3 fps throughput.

**Engineering Best Practices:** CUDA-accelerated inference, fallback mechanisms, and cross-platform deployment. Demonstrates expertise in multimodal learning, real-time systems, concurrent programming, computer vision, and NLP.

**[GitHub](https://github.com/sudo-YashBhardwaj/Multimodal-Emotion-Recogniton)**

