---
permalink: /
title: "ğŸ‘‹ Hello there! I'm Yash"
excerpt: "About me"
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---

![Illustration of combining vision and language modalities](/images/multi_modal_ai.png){: .align-right width="300px"}

ğŸ‘¨ğŸ»â€ğŸ“ Iâ€™m a masterâ€™s student in **Trustworthy & Responsible AI (TRAI)** at **[Ã‰cole Polytechnique](https://www.polytechnique.edu/en)**/

ğŸ”¬ My research interests are at the intersection of **multimodal AI** (vision, audio and language) and **reliable/efficient LLM & VLM systems**. 

ğŸ“š I am currently collaborating with Georgia Techâ€™s **[Financial Services Innovation Lab](https://qcf.gatech.edu/partner)** on problems in multimodal finance.

ğŸ” **Actively seeking research internships (Spring/Summer 2026)** in **multimodal learning**, **alignment**, and **training LLMs/VLMs** - Europe (FR/EU) preferred, open worldwide.
> 
> I love end-to-end work: data â†’ modeling â†’ eval â†’ lightweight demos.

### What Iâ€™m focused on now
- ğŸ¥ **Multimodal learning & generation:** Videoâ€“audioâ€“text fusion, long-range temporal reasoning, controllable generation.
- ğŸ‘ï¸ **Computer vision:** Video understanding, detection/segmentation, retrieval, vision-language grounding.
- ğŸ§© **Alignment & reliability:** Preference/contrastive learning, eval pipelines, robustness/bias checks, model monitoring.
- âš™ï¸ **Systems & efficiency:** Memory/latency-aware inference, reproducible data/workflows, simple productizable demos.

# Selected Highlights

## Research Experiences
- **[VideoConviction (KDD 2025)](https://papers.ssrn.com/sol3/papers.cfm?abstract_id=5315526):** Benchmarking conviction of YouTube fin-fluencer's stock market recommendations.
- **Multimodal captioning pipeline:** Generating dense-video captions on varying combination of modalities (video, audio, text) across model families (OpenAI, Qwen, Gemini, Phi, etc.) and evaluation using reference free methods (GEval, PAC-S)

### Background
- ğŸ“ **MSc&T Trustworthy and Responsible AI (M1)**: [Ã‰cole Polytechnique](https://www.polytechnique.edu/en) (current)  
- ğŸ“ **B.E., Computer Science**: [BITS Pilani](https://www.bits-pilani.ac.in/), India
- ğŸ§ª **Research**: [Georgia Tech](https://www.gatech.edu/) (multimodal finance), [IIIT-Delhi](https://midas.iiitd.ac.in/bio) (author profiling, citation/keyphrase gen)


### Letâ€™s collaborate
Iâ€™m especially interested in **alignment for VLMs**, **multimodal representation learning**, **evaluation of generative models**, and **efficient training/inference**.  
If youâ€™re building in these areas, Iâ€™d love to chat about internships or collaborations.