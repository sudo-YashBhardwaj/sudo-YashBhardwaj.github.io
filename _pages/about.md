---
permalink: /
title: "👋 Hello there! I'm Yash"
excerpt: "About me"
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---

![Illustration of combining vision and language modalities](/images/multi_modal_ai.png){: .align-right width="300px"}

👨🏻‍🎓 I’m a master’s student in **Trustworthy & Responsible AI (TRAI)** at **[École Polytechnique](https://www.polytechnique.edu/en)**/

🔬 My research interests are at the intersection of **multimodal AI** (vision, audio and language) and **reliable/efficient LLM & VLM systems**. 

📚 I am currently collaborating with Georgia Tech’s **[Financial Services Innovation Lab](https://qcf.gatech.edu/partner)** on problems in multimodal finance.

🔎 **Actively seeking research internships (Spring/Summer 2026)** in **multimodal learning**, **alignment**, and **training LLMs/VLMs** - Europe (FR/EU) preferred, open worldwide.
> 
> I love end-to-end work: data → modeling → eval → lightweight demos.

### What I’m focused on now
- 🎥 **Multimodal learning & generation:** Video–audio–text fusion, long-range temporal reasoning, controllable generation.
- 👁️ **Computer vision:** Video understanding, detection/segmentation, retrieval, vision-language grounding.
- 🧩 **Alignment & reliability:** Preference/contrastive learning, eval pipelines, robustness/bias checks, model monitoring.
- ⚙️ **Systems & efficiency:** Memory/latency-aware inference, reproducible data/workflows, simple productizable demos.

# Selected Highlights

## Research Experiences
- **[VideoConviction (KDD 2025)](https://papers.ssrn.com/sol3/papers.cfm?abstract_id=5315526):** Benchmarking conviction of YouTube fin-fluencer's stock market recommendations.
- **Multimodal captioning pipeline:** Generating dense-video captions on varying combination of modalities (video, audio, text) across model families (OpenAI, Qwen, Gemini, Phi, etc.) and evaluation using reference free methods (GEval, PAC-S)

### Background
- 🎓 **MSc&T Trustworthy and Responsible AI (M1)**: [École Polytechnique](https://www.polytechnique.edu/en) (current)  
- 🎓 **B.E., Computer Science**: [BITS Pilani](https://www.bits-pilani.ac.in/), India
- 🧪 **Research**: [Georgia Tech](https://www.gatech.edu/) (multimodal finance), [IIIT-Delhi](https://midas.iiitd.ac.in/bio) (author profiling, citation/keyphrase gen)


### Let’s collaborate
I’m especially interested in **alignment for VLMs**, **multimodal representation learning**, **evaluation of generative models**, and **efficient training/inference**.  
If you’re building in these areas, I’d love to chat about internships or collaborations.